# Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models (2025)

This repository serves as the **overview and entry point** for the code and experiments presented in our paper:

**Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models**

Our goal is to provide **full reproducibility** of all experiments in the paper. Below, you will find links to the individual repositories for each method, along with instructions on how to set up the experiment framework.

## 📌 Overview of Implemented Methods

This repository does not contain code for a specific method itself but serves as a central hub linking to the repositories of all compared approaches:

### Recently Proposed Methods
- [🔗 RAPTOR](https://github.com/Lightnz/raptor-eval) -TODO: change to new repo
- [🔗 ReadAgent](https://github.com/Lightnz/read-agent)

### RAG Baselines
- [🔗 Vanilla RAG](https://github.com/Lightnz/vanilla-rag)
- [🔗 DOS RAG](https://github.com/Lightnz/dos-rag)


## 🏗️ Reproducing the Experiments

To **fully reproduce our experiments**, please follow these steps:

1. **Clone the relevant repositories** from the list above:
2. Follow the setup instructions in each repository's README to install dependencies.
3. Run the provided scripts to prepare datasets, execute experiments and generate results.

We aim to make our research fully transparent and reproducible for anyone interested in RAG benchmarking.

## 📜 Citation

If you use this work in your research, please cite our paper:

    Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models

## 🛠️ Questions & Contributions

We welcome any feedback or contributions. If you have questions or issues, feel free to open an Issue in the respective method's repository.
